{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer-learning on EffNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGO-kRxUUd4n"
   },
   "outputs": [],
   "source": [
    "!pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KykyBexCUal3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install -U keras-efficientnet-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "3PRLO1YLGWrB"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import splitfolders\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "8ZB1TAP4NtSr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard, BackupAndRestore\n",
    "# from tensorflow.keras.callbacks.experimental import BackupAndRestore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "MgvULgRSN5Vz"
   },
   "outputs": [],
   "source": [
    "def path_join(dirname, filenames):\n",
    "    return [os.path.join(dirname, filename) for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "0Sa9KYPPM0Tt"
   },
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None, smooth=True):\n",
    "\n",
    "    assert len(images) == len(cls_true)\n",
    "\n",
    "    # Create figure with sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "\n",
    "    # Adjust vertical spacing.\n",
    "    if cls_pred is None:\n",
    "        hspace = 0.3\n",
    "    else:\n",
    "        hspace = 0.6\n",
    "    fig.subplots_adjust(hspace=hspace, wspace=0.3)\n",
    "\n",
    "    # Interpolation type.\n",
    "    if smooth:\n",
    "        interpolation = 'spline16'\n",
    "    else:\n",
    "        interpolation = 'nearest'\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # There may be less than 9 images, ensure it doesn't crash.\n",
    "        if i < len(images):\n",
    "            # Plot image.\n",
    "            ax.imshow(images[i],\n",
    "                      interpolation=interpolation)\n",
    "\n",
    "            # Name of the true class.\n",
    "            cls_true_name = class_names[cls_true[i]]\n",
    "\n",
    "            # Show true and predicted classes.\n",
    "            if cls_pred is None:\n",
    "                xlabel = \"True: {0}\".format(cls_true_name)\n",
    "            else:\n",
    "                # Name of the predicted class.\n",
    "                cls_pred_name = class_names[cls_pred[i]]\n",
    "\n",
    "                xlabel = \"True: {0}\\nPred: {1}\".format(cls_true_name, cls_pred_name)\n",
    "\n",
    "            # Show the classes as the label on the x-axis.\n",
    "            ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "bDVh5s3iM0Tu"
   },
   "outputs": [],
   "source": [
    "# Import a function from sklearn to calculate the confusion-matrix.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def print_confusion_matrix(cls_pred):\n",
    "    # cls_pred is an array of the predicted class-number for\n",
    "    # all images in the test-set.\n",
    "\n",
    "    # Get the confusion matrix using sklearn.\n",
    "    cm = confusion_matrix(y_true=cls_test,  # True class for test-set.\n",
    "                          y_pred=cls_pred)  # Predicted class.\n",
    "\n",
    "    print(\"Confusion matrix:\")\n",
    "    \n",
    "    # Print the confusion matrix as text.\n",
    "    print(cm)\n",
    "    \n",
    "    # Print the class-names for easy reference.\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(\"({0}) {1}\".format(i, class_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "m_TbQbrBM0Tv"
   },
   "outputs": [],
   "source": [
    "def plot_example_errors(cls_pred):\n",
    "    # cls_pred is an array of the predicted class-number for\n",
    "    # all images in the test-set.\n",
    "\n",
    "    # Boolean array whether the predicted class is incorrect.\n",
    "    incorrect = (cls_pred != cls_test)\n",
    "\n",
    "    # Get the file-paths for images that were incorrectly classified.\n",
    "    image_paths = np.array(image_paths_test)[incorrect]\n",
    "\n",
    "    # Load the first 9 images.\n",
    "    images = load_images(image_paths=image_paths[0:9])\n",
    "    \n",
    "    # Get the predicted classes for those images.\n",
    "    cls_pred = cls_pred[incorrect]\n",
    "\n",
    "    # Get the true classes for those images.\n",
    "    cls_true = cls_test[incorrect]\n",
    "    \n",
    "    # Plot the 9 images we have loaded and their corresponding classes.\n",
    "    # We have only loaded 9 images so there is no need to slice those again.\n",
    "    plot_images(images=images,\n",
    "                cls_true=cls_true[0:9],\n",
    "                cls_pred=cls_pred[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "dOItNq3eM0Tv"
   },
   "outputs": [],
   "source": [
    "def example_errors():\n",
    "    # The Keras data-generator for the test-set must be reset\n",
    "    # before processing. This is because the generator will loop\n",
    "    # infinitely and keep an internal index into the dataset.\n",
    "    # So it might start in the middle of the test-set if we do\n",
    "    # not reset it first. This makes it impossible to match the\n",
    "    # predicted classes with the input images.\n",
    "    # If we reset the generator, then it always starts at the\n",
    "    # beginning so we know exactly which input-images were used.\n",
    "    generator_test.reset()\n",
    "    \n",
    "    # Predict the classes for all images in the test-set.\n",
    "    y_pred = new_model.predict(generator_test, steps=steps_test)\n",
    "\n",
    "    # Convert the predicted classes from arrays to integers.\n",
    "    cls_pred = np.argmax(y_pred,axis=1)\n",
    "\n",
    "    # Plot examples of mis-classified images.\n",
    "    plot_example_errors(cls_pred)\n",
    "    \n",
    "    # Print the confusion matrix.\n",
    "    print_confusion_matrix(cls_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "q2A7S7vZM0Tw"
   },
   "outputs": [],
   "source": [
    "def load_images(image_paths):\n",
    "    # Load the images from disk.\n",
    "    images = [plt.imread(path) for path in image_paths]\n",
    "\n",
    "    # Convert to a numpy array and return it.\n",
    "    return np.asarray(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "L6zJ4rdcM0Tx"
   },
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    # Get the classification accuracy and loss-value\n",
    "    # for the training-set.\n",
    "    acc = history.history['categorical_accuracy']\n",
    "    loss = history.history['loss']\n",
    "\n",
    "    # Get it for the validation-set (we only use the test-set).\n",
    "    val_acc = history.history['val_categorical_accuracy']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    # Plot the accuracy and loss-values for the training-set.\n",
    "    plt.plot(acc, linestyle='-', color='b', label='Training Acc.')\n",
    "    plt.plot(loss, 'o', color='b', label='Training Loss')\n",
    "    \n",
    "    # Plot it for the test-set.\n",
    "    plt.plot(val_acc, linestyle='--', color='r', label='Test Acc.')\n",
    "    plt.plot(val_loss, 'o', color='r', label='Test Loss')\n",
    "\n",
    "    # Plot title and legend.\n",
    "    plt.title('Training and Test Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Ensure the plot shows correctly.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "uotmyBpbOI4I"
   },
   "outputs": [],
   "source": [
    "# dataset_dir = '/content/drive/MyDrive/SleepyWheels/dataset'\n",
    "# output_dataset_dir = '/content/drive/MyDrive/SleepyWheels/split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "4AzuoC5SUUnZ"
   },
   "outputs": [],
   "source": [
    "# Train-Val split\n",
    "# splitfolders.ratio(dataset_dir, output=output_dataset_dir, seed=1337, ratio=(.9, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "G8UpZIxoFvEl"
   },
   "outputs": [],
   "source": [
    "train_dir = '/data/urk18cs085/dataset/train'\n",
    "test_dir = '/data/urk18cs085/dataset/val'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0cTFHx6U3dL"
   },
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G35ZMQqDGtR-",
    "outputId": "9b97146b-b8d3-46da-d7cf-a86d4e848c22"
   },
   "outputs": [],
   "source": [
    "import keras_efficientnet_v2\n",
    "model = keras_efficientnet_v2.EfficientNetV2B0(dropout=1e-6, num_classes=0, pretrained=\"imagenet\")\n",
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QoMGyMNkPKDx"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_k9i6ddICn4",
    "outputId": "949eef5f-af8b-4648-c50e-76e755ade45e"
   },
   "outputs": [],
   "source": [
    "input_shape = model.layers[0].output_shape[0][1:3]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "SBDcAE4wWhEG"
   },
   "outputs": [],
   "source": [
    "datagen_train = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=180,\n",
    "      width_shift_range=0.1,\n",
    "      height_shift_range=0.1,\n",
    "      shear_range=0.1,\n",
    "      zoom_range=[0.9, 1.5],\n",
    "      brightness_range=[0.5,1.1],\n",
    "      horizontal_flip=True,\n",
    "      vertical_flip=True,\n",
    "      fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "9ga3mgNGWjwH"
   },
   "outputs": [],
   "source": [
    "datagen_test = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "k44xIev0Wxa2"
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V0QOmtddW1EO",
    "outputId": "6640892b-815a-4789-86d2-3ec6970819a0"
   },
   "outputs": [],
   "source": [
    "generator_train = datagen_train.flow_from_directory(directory=train_dir,\n",
    "                                                    target_size=input_shape,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vaxWwRDgFo_-",
    "outputId": "5186a497-f9c8-4823-8af3-454695860a9e"
   },
   "outputs": [],
   "source": [
    "generator_test = datagen_test.flow_from_directory(directory=test_dir,\n",
    "                                                  target_size=input_shape,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "TPime5aN0J0f"
   },
   "outputs": [],
   "source": [
    "# Check generated images\n",
    "# x = train_img_gen.next()\n",
    "# for i in range(0,4):\n",
    "#     image = x[i]\n",
    "#     plt.imshow(image)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13zB3CEwGFf9",
    "outputId": "02adffaf-c70a-4d70-ab1c-7bb9e411371e"
   },
   "outputs": [],
   "source": [
    "steps_test = generator_test.n / batch_size\n",
    "steps_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "RELDu7obGQWd"
   },
   "outputs": [],
   "source": [
    "image_paths_train = path_join(train_dir, generator_train.filenames)\n",
    "image_paths_test = path_join(test_dir, generator_test.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "yP03dgnYGXg-"
   },
   "outputs": [],
   "source": [
    "cls_train = generator_train.classes\n",
    "cls_test = generator_test.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgjpZtp2GaTG",
    "outputId": "e8772952-6155-4222-cd7e-6e9ceaae7a81"
   },
   "outputs": [],
   "source": [
    "class_names = list(generator_train.class_indices.keys())\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-rSDqZbGdjW",
    "outputId": "0ccc0ac4-cd94-462d-d880-bbe664962539"
   },
   "outputs": [],
   "source": [
    "num_classes = generator_train.num_classes\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "efHAzWPNGhYH",
    "outputId": "01101f84-c75c-4dfe-c2e4-368b641795f2"
   },
   "outputs": [],
   "source": [
    "# Load the first images from the train-set.\n",
    "images = load_images(image_paths=image_paths_train[0:9])\n",
    "\n",
    "# Get the true classes for those images.\n",
    "cls_true = cls_train[0:9]\n",
    "\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images=images, cls_true=cls_true, smooth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "YgY_sUNkGtrP"
   },
   "outputs": [],
   "source": [
    "def predict(image_path):\n",
    "    # Load and resize the image using PIL.\n",
    "    img = PIL.Image.open(image_path)\n",
    "    img_resized = img.resize(input_shape, PIL.Image.LANCZOS)\n",
    "\n",
    "    # Plot the image.\n",
    "    plt.imshow(img_resized)\n",
    "    plt.show()\n",
    "\n",
    "    # Convert the PIL image to a numpy-array with the proper shape.\n",
    "    img_array = np.expand_dims(np.array(img_resized), axis=0)\n",
    "\n",
    "    # Use the model to make a prediction.\n",
    "    # This outputs an array with 2 numbers corresponding to\n",
    "    # the classes of the dataset.\n",
    "    pred = model.predict(img_array)\n",
    "    \n",
    "    # Decode the output of the model.\n",
    "    pred_decoded = decode_predictions(pred)[0]\n",
    "\n",
    "    # Print the predictions.\n",
    "    for code, name, score in pred_decoded:\n",
    "        print(\"{0:>6.2%} : {1}\".format(score, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "AXiLqHnlHC-m"
   },
   "outputs": [],
   "source": [
    "# predict(image_path=image_paths_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "wZ3e8ONgHVK6"
   },
   "outputs": [],
   "source": [
    "# predict(image_path=image_paths_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRHH5YuKH47e"
   },
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-LPTvj1HYmO"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "8gkm9n8NH8Uv"
   },
   "outputs": [],
   "source": [
    "# transfer_layer = model.get_layer('layer_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Kj6ipKKlIypo"
   },
   "outputs": [],
   "source": [
    "# transfer_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "zcqQ3RTjI1Sa"
   },
   "outputs": [],
   "source": [
    "# conv_model = Model(inputs=model.input,\n",
    "#                    outputs=transfer_layer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Z8fRB0r3Zccz"
   },
   "outputs": [],
   "source": [
    "conv_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "kUvR6lbtI3XK"
   },
   "outputs": [],
   "source": [
    "# Start a new Keras Sequential model.\n",
    "new_model = Sequential()\n",
    "\n",
    "# Add the convolutional part of the EffNetV2 model from above.\n",
    "new_model.add(conv_model)\n",
    "\n",
    "# Flatten the output of the EffNetV2 model because it is from a\n",
    "# convolutional layer.\n",
    "new_model.add(Flatten())\n",
    "\n",
    "# Add a dense (aka. fully-connected) layer.\n",
    "# This is for combining features that the EffNetV2 model has\n",
    "# recognized in the image.\n",
    "new_model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "# Add a dropout-layer which may prevent overfitting and\n",
    "# improve generalization ability to unseen data e.g. the test-set.\n",
    "new_model.add(Dropout(0.7))\n",
    "\n",
    "# Add the final layer for the actual classification.\n",
    "new_model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "GhR7ny56I5Oa"
   },
   "outputs": [],
   "source": [
    "optimizer = Nadam(learning_rate=3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "42V1vYIII7lS"
   },
   "outputs": [],
   "source": [
    "loss = 'categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "c1jk-1DRI9Vc"
   },
   "outputs": [],
   "source": [
    "metrics = ['categorical_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "lNirZ-v8I_Ka"
   },
   "outputs": [],
   "source": [
    "def print_layer_trainable():\n",
    "    for layer in conv_model.layers:\n",
    "        print(\"{0}:\\t{1}\".format(layer.trainable, layer.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-NlFgGYfJG9-"
   },
   "outputs": [],
   "source": [
    "print_layer_trainable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "x-r-_xFdJIxi"
   },
   "outputs": [],
   "source": [
    "conv_model.trainable = False\n",
    "\n",
    "for layer in conv_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edRv7minJLwN"
   },
   "outputs": [],
   "source": [
    "print_layer_trainable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "TotyVVkfJSVW"
   },
   "outputs": [],
   "source": [
    "new_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "cYrOKz3sJVgu"
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "# steps_per_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvcBW2iybGpG",
    "outputId": "334459da-13a9-4e68-d31c-d793f63bffad",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "steps_train = generator_train.n / batch_size\n",
    "steps_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "vXC51PgVeQvf"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = '/data/urk18cs085/saved_models/transfer_learnt_best_27thFeb.h5'\n",
    "checkpoint = ModelCheckpoint(checkpoint_path,\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "backup_path = '/data/urk18cs085/backup'\n",
    "backup = BackupAndRestore(backup_path)\n",
    "\n",
    "lrr = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=.01, patience=3, min_lr=1e-4)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 5,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "tb = TensorBoard(log_dir='./TransferLearntGraph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "callbacks = [checkpoint, backup, lrr, earlystop, tb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fwQrXzvdJlrP",
    "outputId": "70374c0d-962d-4664-95cc-b1921be7dd97",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = new_model.fit(x=generator_train,\n",
    "                        epochs=epochs,\n",
    "                        steps_per_epoch=steps_train,\n",
    "                        callbacks = callbacks,\n",
    "                        validation_data=generator_test,\n",
    "                        validation_steps=steps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rRhBixLRJsAl"
   },
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qlgUnxEEJ58L",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "example_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y tensorboard tb-nightly\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir './TransferLearntGraph' --port 8889 --bind_all\n",
    "# %tensorboard --logdir './TransferLearntGraph/train/events.out.tfevents.1645980487.starship2.7312.0.v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list() # View open TensorBoard instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "transfer_learnt_filepath = '/data/urk18cs085/saved_models/transfer_learnt_best_27thFeb.h5'\n",
    "transfer_learnt_model = load_model(transfer_learnt_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_learnt_model.evaluate(generator_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in conv_model.layers:\n",
    "#     # Boolean whether this layer is trainable.\n",
    "#     selected_layers = ['post_swish', 'post_bn', 'post_conv', 'add_14', 'stack_5_block7_MB_pw_bn', 'stack_5_block7_MB_pw_conv', 'multiply_15']\n",
    "# #     selected_layers = ['post_swish', 'post_bn', 'post_conv']\n",
    "#     trainable = (layer.name in selected_layers)\n",
    "    \n",
    "#     # Set the layer's bool.\n",
    "#     layer.trainable = trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in transfer_learnt_model.layers:\n",
    "    print(\"{0}:\\t{1}\".format(layer.trainable, layer.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in transfer_learnt_model.layers:\n",
    "    layer.trainable = False\n",
    "    if layer.name == 'EfficientNetV2B0':\n",
    "        for inner_layer in layer.layers:\n",
    "            print(\"{0}:\\t{1}\".format(inner_layer.trainable, inner_layer.name))\n",
    "            inner_layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_learnt_model.trainable = True\n",
    "\n",
    "selected_before = ['dense_1', \n",
    "                   'dropout', \n",
    "                   'dense', \n",
    "                   'flatten']\n",
    "\n",
    "selected_for_finetuning = ['post_swish', \n",
    "                           'post_bn', \n",
    "                           'post_conv', \n",
    "                           'add_14', \n",
    "                           'stack_5_block7_MB_pw_bn', \n",
    "                           'stack_5_block7_MB_pw_conv', \n",
    "                           'multiply_15']\n",
    "\n",
    "for layer in transfer_learnt_model.layers:\n",
    "    layer.trainable = True\n",
    "    if layer.name == 'EfficientNetV2B0':\n",
    "        for inner_layer in layer.layers:\n",
    "#             if inner_layer.name not in selected_for_finetuning:\n",
    "                inner_layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in transfer_learnt_model.layers:\n",
    "        print(\"{0}:\\t{1}\".format(layer.trainable, layer.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in transfer_learnt_model.layers:\n",
    "    if layer.name == 'EfficientNetV2B0':\n",
    "        for inner_layer in layer.layers:\n",
    "            print(\"{0}:\\t{1}\".format(inner_layer.trainable, inner_layer.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_learnt_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_fine = Nadam(learning_rate=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_learnt_model.compile(optimizer=optimizer_fine, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/data/urk18cs085/saved_models/fine_tuned_best_28Feb.h5'\n",
    "checkpoint = ModelCheckpoint(checkpoint_path,\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "lrr = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=.01, patience=3, min_lr=1e-5)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 4,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "backup_path = '/data/urk18cs085/finetune_backup'\n",
    "backup = BackupAndRestore(backup_path)\n",
    "\n",
    "tb = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "callbacks = [checkpoint, lrr, earlystop, backup, tb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = transfer_learnt_model.fit(x=generator_train,\n",
    "                        epochs=epochs,\n",
    "                        steps_per_epoch=steps_train,\n",
    "                        callbacks = callbacks,\n",
    "                        validation_data=generator_test,\n",
    "                        validation_steps=steps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = transfer_learnt_model.evaluate(generator_test, steps=steps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test-set classification accuracy: {0:.2%}\".format(result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir './Graph' --port 8890 --bind_all"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "EffNetV2 Sleepy Classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
