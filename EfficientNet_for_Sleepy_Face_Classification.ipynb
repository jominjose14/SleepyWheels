{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNet for Sleepy Face Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "10hxAUv8ky2XslInnAwjtBJVMdAEieHPf",
      "authorship_tag": "ABX9TyNaLXknE67PxSHwAMHy/2lK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jominjose14/SleepyWheels/blob/main/EfficientNet_for_Sleepy_Face_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "ljkjK_JZpzid",
        "outputId": "8c425e0e-97c8-4629-bddd-78bc69a2a6f4"
      },
      "source": [
        "# Downgrade pillow to avoid `UserWarning: Possibly corrupt EXIF data.`\n",
        "!pip install pillow==4.0.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pillow==4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/80/eca7a2d1a3c2dafb960f32f844d570de988e609f5fd17de92e1cf6a01b0a/Pillow-4.0.0.tar.gz (11.1MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1MB 7.2MB/s \n",
            "\u001b[?25hCollecting olefile\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/81/e1ac43c6b45b4c5f8d9352396a14144bba52c8fec72a80f425f6a4d653ad/olefile-0.46.zip (112kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 61.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pillow, olefile\n",
            "  Building wheel for pillow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pillow: filename=Pillow-4.0.0-cp37-cp37m-linux_x86_64.whl size=1007423 sha256=b20a82b8af8e08c7a55d565c8c35bf9397286ffa5980b55df1ae7bb51e904200\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/0a/2a/7e3391063af230fac4b5fdb4cc93adcb1d99af325b623cea03\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35416 sha256=6b782f6be5bc5f4b268c4e7477ec411773667789c08677e6325a4612cadc072c\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/f4/11/bc4166107c27f07fd7bba707ffcb439619197638a1ac986df3\n",
            "Successfully built pillow olefile\n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: scikit-image 0.16.2 has requirement pillow>=4.3.0, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: bokeh 2.3.2 has requirement pillow>=7.1.0, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: olefile, pillow\n",
            "  Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "Successfully installed olefile-0.46 pillow-4.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQl4ZKWwyZ9z",
        "outputId": "a82bb95f-c903-4ff0-b6f0-d9ce79525e0e"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqZC_nn8VL1D",
        "outputId": "192efc5a-0d39-4b39-ae65-17b079aa15f5"
      },
      "source": [
        "import tensorflow.keras\n",
        "print(tensorflow.__version__)\n",
        "print(tensorflow.keras.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIfvhBPIsz0p"
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk8HlfoytBhX"
      },
      "source": [
        "## **Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMLqCmFxs4fI"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 50\n",
        "NUM_TRAIN = 2103\n",
        "NUM_TEST = 400\n",
        "dropout_rate = 0.4\n",
        "input_shape = (height, width, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn480PuOtmqR",
        "outputId": "be16972d-d405-457e-a0db-6fd0972b8633"
      },
      "source": [
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        "  !git clone https://github.com/Tony607/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0X3lJsJhtzgv",
        "outputId": "e9f1f6cc-9d24-4dbe-e749-24fcff118868"
      },
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRvaOts7t_0Y",
        "outputId": "9971f3ba-fe46-4f76-8fea-775202fafdba"
      },
      "source": [
        "# loading pretrained conv base model\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/efficientnet_keras_transfer_learning/efficientnet/model.py:67: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa76c0db310>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa76c0db310>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b2f7ad0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b2f7ad0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b32d850>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b32d850>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75c5abc90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75c5abc90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b412410>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b412410>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b3e1d90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b3e1d90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b3cb3d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b3cb3d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b3897d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b3897d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b2c5110>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b2c5110>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75b276c90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75b276c90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:From /content/efficientnet_keras_transfer_learning/efficientnet/layers.py:28: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/efficientnet_keras_transfer_learning/efficientnet/layers.py:30: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b240190>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b240190>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b193990>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b193990>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b1aded0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b1aded0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b1b5f10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b1b5f10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b0ed110>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b0ed110>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b106610>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b106610>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75b04f550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75b04f550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b030350>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b030350>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75aff8fd0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75aff8fd0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75af96e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75af96e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75afc88d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75afc88d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75aee5590>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75aee5590>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75aebfc10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75aebfc10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75aec81d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75aec81d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75ae24f10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75ae24f10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75ae00890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75ae00890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75adb3950>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75adb3950>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75ad64250>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75ad64250>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75ad20550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75ad20550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75ad16a50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75ad16a50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75acc9990>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75acc9990>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75ac23350>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75ac23350>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75abf1850>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75abf1850>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75adcc890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75adcc890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75ab51e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75ab51e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75ab13e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75ab13e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75aaddf50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75aaddf50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75aab09d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75aab09d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75aacd750>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75aacd750>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75aa13750>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75aa13750>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a9e1890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a9e1890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a9bcf90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a9bcf90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a969190>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a969190>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a9c3e90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a9c3e90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a8f4350>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a8f4350>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75a8c5990>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75a8c5990>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a814510>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a814510>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a7d1f90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a7d1f90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a7c6990>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a7c6990>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75a768090>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75a768090>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a71eed0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a71eed0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a6ea250>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a6ea250>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a6f7550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a6f7550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75a65de10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75a65de10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a64e5d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a64e5d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a5f3d90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a5f3d90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a5c9850>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a5c9850>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a55c810>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a55c810>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkEFf7lnuEPz"
      },
      "source": [
        "train_data_dir = '/content/drive/MyDrive/Sleepy or Awake Faces - Dataset/train'\n",
        "validation_data_dir = '/content/drive/MyDrive/Sleepy or Awake Faces - Dataset/validation'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nrnLg0_xc5F",
        "outputId": "8764b999-d777-41fc-f67c-9c26e6906dee"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory\n",
        "        train_data_dir,\n",
        "        # All images will be resized to target height and width.\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2103 images belonging to 2 classes.\n",
            "Found 400 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwSVd8ugyIpk",
        "outputId": "35bbc2c9-77e6-4340-db2c-4fff513ecc51"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(1, activation='sigmoid', name=\"fc_out\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa76c0db310>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa76c0db310>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b2f7ad0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b2f7ad0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b32d850>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b32d850>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75c5abc90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75c5abc90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b412410>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b412410>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b3e1d90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b3e1d90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b3cb3d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b3cb3d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b3897d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b3897d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b2c5110>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b2c5110>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75b276c90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75b276c90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b240190>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b240190>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b193990>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b193990>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b1aded0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b1aded0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b1b5f10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b1b5f10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b0ed110>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b0ed110>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b106610>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b106610>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75b04f550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75b04f550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b030350>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75b030350>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75aff8fd0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75aff8fd0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75af96e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75af96e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75afc88d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75afc88d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75aee5590>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75aee5590>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75aebfc10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75aebfc10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75aec81d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75aec81d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75ae24f10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75ae24f10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75ae00890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75ae00890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75adb3950>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75adb3950>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75ad64250>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75ad64250>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75ad20550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75ad20550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75ad16a50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75ad16a50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75acc9990>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75acc9990>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75ac23350>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75ac23350>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75abf1850>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75abf1850>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75adcc890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75adcc890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75ab51e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75ab51e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75ab13e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75ab13e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75aaddf50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75aaddf50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75aab09d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75aab09d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75aacd750>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75aacd750>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75aa13750>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75aa13750>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a9e1890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a9e1890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a9bcf90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a9bcf90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a969190>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a969190>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a9c3e90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a9c3e90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a8f4350>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a8f4350>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75a8c5990>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75a8c5990>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a814510>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a814510>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a7d1f90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a7d1f90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a7c6990>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a7c6990>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75a768090>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75a768090>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a71eed0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a71eed0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a6ea250>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a6ea250>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a6f7550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a6f7550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75a65de10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method DropConnect.call of <efficientnet.layers.DropConnect object at 0x7fa75a65de10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a64e5d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a64e5d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a5f3d90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a5f3d90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a5c9850>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a5c9850>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a55c810>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Swish.call of <efficientnet.layers.Swish object at 0x7fa75a55c810>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJggD32Kz0Cc",
        "outputId": "4d3eb60a-1ec4-432e-e96d-6cea1c88c85d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "efficientnet-b0 (Model)      (None, 5, 5, 1280)        4049564   \n",
            "_________________________________________________________________\n",
            "gap (GlobalMaxPooling2D)     (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dropout_out (Dropout)        (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 256)               327936    \n",
            "_________________________________________________________________\n",
            "fc_out (Dense)               (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 4,377,757\n",
            "Trainable params: 4,335,741\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBaet_G_0HaM"
      },
      "source": [
        "### **Freezing the Conv Layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNOgdmISz5rs",
        "outputId": "a130dec5-5c98-499e-f933-a00e28b5b13f"
      },
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 215\n",
            "This is the number of trainable layers after freezing the conv base: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGEyzP6k02Qw",
        "outputId": "e712e7c5-9e4e-416a-f532-886dc9ed7d8b"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "efficientnet-b0 (Model)      (None, 5, 5, 1280)        4049564   \n",
            "_________________________________________________________________\n",
            "gap (GlobalMaxPooling2D)     (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dropout_out (Dropout)        (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 256)               327936    \n",
            "_________________________________________________________________\n",
            "fc_out (Dense)               (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 4,377,757\n",
            "Trainable params: 328,193\n",
            "Non-trainable params: 4,049,564\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_wXUk-z0C0s",
        "outputId": "4695f0be-c5c6-4a17-bc95-dfaa406799cf"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['binary_accuracy'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/50\n",
            "19/32 [================>.............] - ETA: 2:47 - loss: 1.4906 - binary_accuracy: 0.5115"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 12s - loss: 1.4356 - binary_accuracy: 0.5230Epoch 1/50\n",
            "32/32 [==============================] - 460s 14s/step - loss: 1.4521 - binary_accuracy: 0.5213 - val_loss: 0.9424 - val_binary_accuracy: 0.5677\n",
            "Epoch 2/50\n",
            "13/32 [===========>..................] - ETA: 10s - loss: 1.2271 - binary_accuracy: 0.5204"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "21/32 [==================>...........] - ETA: 6s - loss: 1.2390 - binary_accuracy: 0.5290"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 1.2158 - binary_accuracy: 0.5438Epoch 1/50\n",
            "32/32 [==============================] - 21s 649ms/step - loss: 1.2208 - binary_accuracy: 0.5439 - val_loss: 0.9188 - val_binary_accuracy: 0.5859\n",
            "Epoch 3/50\n",
            " 8/32 [======>.......................] - ETA: 14s - loss: 1.1479 - binary_accuracy: 0.5566"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "14/32 [============>.................] - ETA: 9s - loss: 1.1906 - binary_accuracy: 0.5413 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 1.1985 - binary_accuracy: 0.5489Epoch 1/50\n",
            "32/32 [==============================] - 21s 655ms/step - loss: 1.2008 - binary_accuracy: 0.5493 - val_loss: 0.9121 - val_binary_accuracy: 0.6068\n",
            "Epoch 4/50\n",
            " 7/32 [=====>........................] - ETA: 11s - loss: 1.2129 - binary_accuracy: 0.5330"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 1.1253 - binary_accuracy: 0.5737Epoch 1/50\n",
            "32/32 [==============================] - 21s 652ms/step - loss: 1.1265 - binary_accuracy: 0.5738 - val_loss: 0.9205 - val_binary_accuracy: 0.6172\n",
            "Epoch 5/50\n",
            "10/32 [========>.....................] - ETA: 11s - loss: 1.0843 - binary_accuracy: 0.5891"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 1.0728 - binary_accuracy: 0.5995"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 21s 645ms/step - loss: 1.0727 - binary_accuracy: 0.6003 - val_loss: 0.8248 - val_binary_accuracy: 0.6536\n",
            "Epoch 6/50\n",
            "13/32 [===========>..................] - ETA: 8s - loss: 1.0420 - binary_accuracy: 0.6250"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 1.0002 - binary_accuracy: 0.6203Epoch 1/50\n",
            "32/32 [==============================] - 21s 646ms/step - loss: 0.9931 - binary_accuracy: 0.6219 - val_loss: 0.7792 - val_binary_accuracy: 0.6615\n",
            "Epoch 7/50\n",
            " 6/32 [====>.........................] - ETA: 2s - loss: 0.9208 - binary_accuracy: 0.6406"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/32 [========>.....................] - ETA: 8s - loss: 0.9715 - binary_accuracy: 0.6422"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.9619 - binary_accuracy: 0.6359Epoch 1/50\n",
            "32/32 [==============================] - 21s 652ms/step - loss: 0.9624 - binary_accuracy: 0.6351 - val_loss: 0.7834 - val_binary_accuracy: 0.6562\n",
            "Epoch 8/50\n",
            "11/32 [=========>....................] - ETA: 7s - loss: 0.9524 - binary_accuracy: 0.6321"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.8891 - binary_accuracy: 0.6461Epoch 1/50\n",
            "32/32 [==============================] - 21s 654ms/step - loss: 0.8851 - binary_accuracy: 0.6459 - val_loss: 0.7711 - val_binary_accuracy: 0.6562\n",
            "Epoch 9/50\n",
            " 5/32 [===>..........................] - ETA: 2s - loss: 0.8675 - binary_accuracy: 0.6375"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "14/32 [============>.................] - ETA: 6s - loss: 0.8780 - binary_accuracy: 0.6473"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "23/32 [====================>.........] - ETA: 3s - loss: 0.8971 - binary_accuracy: 0.6365"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.8997 - binary_accuracy: 0.6334Epoch 1/50\n",
            "32/32 [==============================] - 19s 609ms/step - loss: 0.8960 - binary_accuracy: 0.6356 - val_loss: 0.7467 - val_binary_accuracy: 0.6771\n",
            "Epoch 10/50\n",
            "22/32 [===================>..........] - ETA: 4s - loss: 0.8481 - binary_accuracy: 0.6733"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.8393 - binary_accuracy: 0.6653Epoch 1/50\n",
            "32/32 [==============================] - 21s 655ms/step - loss: 0.8491 - binary_accuracy: 0.6641 - val_loss: 0.7820 - val_binary_accuracy: 0.6641\n",
            "Epoch 11/50\n",
            " 9/32 [=======>......................] - ETA: 4s - loss: 0.8613 - binary_accuracy: 0.6510"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "20/32 [=================>............] - ETA: 5s - loss: 0.7987 - binary_accuracy: 0.6672"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.7822 - binary_accuracy: 0.6658"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 20s 616ms/step - loss: 0.7835 - binary_accuracy: 0.6655 - val_loss: 0.7715 - val_binary_accuracy: 0.6719\n",
            "Epoch 12/50\n",
            "19/32 [================>.............] - ETA: 5s - loss: 0.7387 - binary_accuracy: 0.6943"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.7775 - binary_accuracy: 0.6867Epoch 1/50\n",
            "32/32 [==============================] - 21s 661ms/step - loss: 0.7768 - binary_accuracy: 0.6877 - val_loss: 0.7407 - val_binary_accuracy: 0.6901\n",
            "Epoch 13/50\n",
            "12/32 [==========>...................] - ETA: 4s - loss: 0.8206 - binary_accuracy: 0.6771"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "22/32 [===================>..........] - ETA: 4s - loss: 0.8035 - binary_accuracy: 0.6762"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.8062 - binary_accuracy: 0.6770Epoch 1/50\n",
            "32/32 [==============================] - 20s 609ms/step - loss: 0.8082 - binary_accuracy: 0.6768 - val_loss: 0.7353 - val_binary_accuracy: 0.6823\n",
            "Epoch 14/50\n",
            "28/32 [=========================>....] - ETA: 1s - loss: 0.7978 - binary_accuracy: 0.6674"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.7916 - binary_accuracy: 0.6714Epoch 1/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 21s 652ms/step - loss: 0.7952 - binary_accuracy: 0.6714 - val_loss: 0.7379 - val_binary_accuracy: 0.6875\n",
            "Epoch 15/50\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.7828 - binary_accuracy: 0.6766"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.7842 - binary_accuracy: 0.6780Epoch 1/50\n",
            "32/32 [==============================] - 21s 641ms/step - loss: 0.7776 - binary_accuracy: 0.6793 - val_loss: 0.6872 - val_binary_accuracy: 0.7083\n",
            "Epoch 16/50\n",
            " 4/32 [==>...........................] - ETA: 3s - loss: 0.8518 - binary_accuracy: 0.6758"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "24/32 [=====================>........] - ETA: 3s - loss: 0.7380 - binary_accuracy: 0.6979"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.7475 - binary_accuracy: 0.6910Epoch 1/50\n",
            "32/32 [==============================] - 21s 657ms/step - loss: 0.7455 - binary_accuracy: 0.6929 - val_loss: 0.7128 - val_binary_accuracy: 0.7057\n",
            "Epoch 17/50\n",
            "23/32 [====================>.........] - ETA: 3s - loss: 0.7797 - binary_accuracy: 0.6816"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.7726 - binary_accuracy: 0.6923"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 20s 619ms/step - loss: 0.7725 - binary_accuracy: 0.6887 - val_loss: 0.7142 - val_binary_accuracy: 0.6927\n",
            "Epoch 18/50\n",
            "28/32 [=========================>....] - ETA: 1s - loss: 0.7089 - binary_accuracy: 0.7020"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.7002 - binary_accuracy: 0.7056Epoch 1/50\n",
            "32/32 [==============================] - 20s 631ms/step - loss: 0.7061 - binary_accuracy: 0.7031 - val_loss: 0.7687 - val_binary_accuracy: 0.6693\n",
            "Epoch 19/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.7481 - binary_accuracy: 0.6876Epoch 1/50\n",
            " 4/32 [==>...........................] - ETA: 23s - loss: 0.7025 - binary_accuracy: 0.7070"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 21s 671ms/step - loss: 0.7463 - binary_accuracy: 0.6876 - val_loss: 0.7074 - val_binary_accuracy: 0.6953\n",
            "Epoch 20/50\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.6980 - binary_accuracy: 0.6942"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 20s 632ms/step - loss: 0.6966 - binary_accuracy: 0.6940 - val_loss: 0.6692 - val_binary_accuracy: 0.7109\n",
            "Epoch 21/50\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.6765 - binary_accuracy: 0.7144Epoch 1/50\n",
            "32/32 [==============================] - 20s 628ms/step - loss: 0.6781 - binary_accuracy: 0.7146 - val_loss: 0.7324 - val_binary_accuracy: 0.6849\n",
            "Epoch 22/50\n",
            "13/32 [===========>..................] - ETA: 6s - loss: 0.6952 - binary_accuracy: 0.7035"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "17/32 [==============>...............] - ETA: 5s - loss: 0.6928 - binary_accuracy: 0.7090"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "21/32 [==================>...........] - ETA: 4s - loss: 0.7093 - binary_accuracy: 0.7011"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.7100 - binary_accuracy: 0.6992Epoch 1/50\n",
            "32/32 [==============================] - 21s 644ms/step - loss: 0.7105 - binary_accuracy: 0.6995 - val_loss: 0.7403 - val_binary_accuracy: 0.6641\n",
            "Epoch 23/50\n",
            "13/32 [===========>..................] - ETA: 6s - loss: 0.6276 - binary_accuracy: 0.7200"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.6570 - binary_accuracy: 0.7107Epoch 1/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 21s 646ms/step - loss: 0.6564 - binary_accuracy: 0.7090 - val_loss: 0.7311 - val_binary_accuracy: 0.6771\n",
            "Epoch 24/50\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.6748 - binary_accuracy: 0.7096Epoch 1/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 1/32 [..............................] - ETA: 1:11 - loss: 0.5937 - binary_accuracy: 0.7344"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 20s 637ms/step - loss: 0.6753 - binary_accuracy: 0.7094 - val_loss: 0.6939 - val_binary_accuracy: 0.7005\n",
            "Epoch 25/50\n",
            "24/32 [=====================>........] - ETA: 3s - loss: 0.6817 - binary_accuracy: 0.7057"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.6759 - binary_accuracy: 0.7033Epoch 1/50\n",
            "32/32 [==============================] - 20s 614ms/step - loss: 0.6781 - binary_accuracy: 0.7018 - val_loss: 0.6854 - val_binary_accuracy: 0.7005\n",
            "Epoch 26/50\n",
            " 8/32 [======>.......................] - ETA: 5s - loss: 0.6600 - binary_accuracy: 0.7090"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.6787 - binary_accuracy: 0.7137Epoch 1/50\n",
            "32/32 [==============================] - 20s 638ms/step - loss: 0.6728 - binary_accuracy: 0.7148 - val_loss: 0.6393 - val_binary_accuracy: 0.7083\n",
            "Epoch 27/50\n",
            " 9/32 [=======>......................] - ETA: 5s - loss: 0.7225 - binary_accuracy: 0.6997"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.6829 - binary_accuracy: 0.7225Epoch 1/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 21s 671ms/step - loss: 0.6771 - binary_accuracy: 0.7244 - val_loss: 0.6810 - val_binary_accuracy: 0.7057\n",
            "Epoch 28/50\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.6560 - binary_accuracy: 0.7099"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 21s 646ms/step - loss: 0.6508 - binary_accuracy: 0.7121 - val_loss: 0.6476 - val_binary_accuracy: 0.7031\n",
            "Epoch 29/50\n",
            " 7/32 [=====>........................] - ETA: 2s - loss: 0.5498 - binary_accuracy: 0.7198"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.6088 - binary_accuracy: 0.7139"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 20s 622ms/step - loss: 0.6093 - binary_accuracy: 0.7151 - val_loss: 0.6954 - val_binary_accuracy: 0.6953\n",
            "Epoch 30/50\n",
            "22/32 [===================>..........] - ETA: 4s - loss: 0.6476 - binary_accuracy: 0.7269"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.6462 - binary_accuracy: 0.7261"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 21s 643ms/step - loss: 0.6446 - binary_accuracy: 0.7273 - val_loss: 0.6260 - val_binary_accuracy: 0.7135\n",
            "Epoch 31/50\n",
            " 6/32 [====>.........................] - ETA: 5s - loss: 0.6624 - binary_accuracy: 0.7161"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "30/32 [===========================>..] - ETA: 0s - loss: 0.6293 - binary_accuracy: 0.7190"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.6235 - binary_accuracy: 0.7215Epoch 1/50\n",
            "32/32 [==============================] - 21s 649ms/step - loss: 0.6210 - binary_accuracy: 0.7219 - val_loss: 0.7173 - val_binary_accuracy: 0.6771\n",
            "Epoch 32/50\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.6522 - binary_accuracy: 0.7235Epoch 1/50\n",
            "32/32 [==============================] - 21s 649ms/step - loss: 0.6498 - binary_accuracy: 0.7239 - val_loss: 0.6576 - val_binary_accuracy: 0.7005\n",
            "Epoch 33/50\n",
            " 1/32 [..............................] - ETA: 6s - loss: 0.4711 - binary_accuracy: 0.7969"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "23/32 [====================>.........] - ETA: 3s - loss: 0.5985 - binary_accuracy: 0.7280"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.5998 - binary_accuracy: 0.7230Epoch 1/50\n",
            "32/32 [==============================] - 18s 563ms/step - loss: 0.6058 - binary_accuracy: 0.7214 - val_loss: 0.7273 - val_binary_accuracy: 0.6693\n",
            "Epoch 34/50\n",
            "12/32 [==========>...................] - ETA: 8s - loss: 0.6335 - binary_accuracy: 0.7292"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "20/32 [=================>............] - ETA: 5s - loss: 0.6111 - binary_accuracy: 0.7289"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.6130 - binary_accuracy: 0.7347Epoch 1/50\n",
            "32/32 [==============================] - 19s 579ms/step - loss: 0.6175 - binary_accuracy: 0.7332 - val_loss: 0.6963 - val_binary_accuracy: 0.6953\n",
            "Epoch 35/50\n",
            "Epoch 1/50\n",
            " 9/32 [=======>......................] - ETA: 13s - loss: 0.6333 - binary_accuracy: 0.7274"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "19/32 [================>.............] - ETA: 8s - loss: 0.6547 - binary_accuracy: 0.7204"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.6437 - binary_accuracy: 0.7154Epoch 1/50\n",
            "32/32 [==============================] - 21s 663ms/step - loss: 0.6453 - binary_accuracy: 0.7160 - val_loss: 0.6687 - val_binary_accuracy: 0.7005\n",
            "Epoch 36/50\n",
            " 6/32 [====>.........................] - ETA: 14s - loss: 0.6306 - binary_accuracy: 0.7173"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 9/32 [=======>......................] - ETA: 13s - loss: 0.6181 - binary_accuracy: 0.7178"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.6035 - binary_accuracy: 0.7332Epoch 1/50\n",
            "32/32 [==============================] - 21s 655ms/step - loss: 0.5968 - binary_accuracy: 0.7357 - val_loss: 0.6778 - val_binary_accuracy: 0.7031\n",
            "Epoch 37/50\n",
            " 8/32 [======>.......................] - ETA: 14s - loss: 0.7328 - binary_accuracy: 0.6719"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "30/32 [===========================>..] - ETA: 1s - loss: 0.6127 - binary_accuracy: 0.7211"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.6166 - binary_accuracy: 0.7205Epoch 1/50\n",
            "32/32 [==============================] - 21s 667ms/step - loss: 0.6196 - binary_accuracy: 0.7195 - val_loss: 0.6846 - val_binary_accuracy: 0.6979\n",
            "Epoch 38/50\n",
            " 8/32 [======>.......................] - ETA: 10s - loss: 0.6737 - binary_accuracy: 0.7031"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.5892 - binary_accuracy: 0.7311Epoch 1/50\n",
            "32/32 [==============================] - 21s 651ms/step - loss: 0.5939 - binary_accuracy: 0.7288 - val_loss: 0.6699 - val_binary_accuracy: 0.6953\n",
            "Epoch 39/50\n",
            "23/32 [====================>.........] - ETA: 4s - loss: 0.5913 - binary_accuracy: 0.7283"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "29/32 [==========================>...] - ETA: 1s - loss: 0.5799 - binary_accuracy: 0.7311"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.5846 - binary_accuracy: 0.7263Epoch 1/50\n",
            "32/32 [==============================] - 21s 660ms/step - loss: 0.5832 - binary_accuracy: 0.7266 - val_loss: 0.6964 - val_binary_accuracy: 0.6901\n",
            "Epoch 40/50\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.6248 - binary_accuracy: 0.7325Epoch 1/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 21s 664ms/step - loss: 0.6248 - binary_accuracy: 0.7320 - val_loss: 0.6922 - val_binary_accuracy: 0.6875\n",
            "Epoch 41/50\n",
            "19/32 [================>.............] - ETA: 5s - loss: 0.6183 - binary_accuracy: 0.7241"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.5996 - binary_accuracy: 0.7347Epoch 1/50\n",
            "32/32 [==============================] - 21s 661ms/step - loss: 0.5997 - binary_accuracy: 0.7361 - val_loss: 0.6671 - val_binary_accuracy: 0.6927\n",
            "Epoch 42/50\n",
            "12/32 [==========>...................] - ETA: 6s - loss: 0.5752 - binary_accuracy: 0.7487"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.5715 - binary_accuracy: 0.7458Epoch 1/50\n",
            "32/32 [==============================] - 20s 615ms/step - loss: 0.5720 - binary_accuracy: 0.7460 - val_loss: 0.6478 - val_binary_accuracy: 0.6927\n",
            "Epoch 43/50\n",
            "17/32 [==============>...............] - ETA: 6s - loss: 0.6639 - binary_accuracy: 0.7086"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25/32 [======================>.......] - ETA: 3s - loss: 0.6496 - binary_accuracy: 0.7153"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.6368 - binary_accuracy: 0.7225Epoch 1/50\n",
            "32/32 [==============================] - 21s 671ms/step - loss: 0.6345 - binary_accuracy: 0.7239 - val_loss: 0.6653 - val_binary_accuracy: 0.6823\n",
            "Epoch 44/50\n",
            "22/32 [===================>..........] - ETA: 4s - loss: 0.5323 - binary_accuracy: 0.7578"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "28/32 [=========================>....] - ETA: 1s - loss: 0.5451 - binary_accuracy: 0.7528"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.5485 - binary_accuracy: 0.7490Epoch 1/50\n",
            "32/32 [==============================] - 21s 649ms/step - loss: 0.5507 - binary_accuracy: 0.7471 - val_loss: 0.6758 - val_binary_accuracy: 0.6901\n",
            "Epoch 45/50\n",
            "25/32 [======================>.......] - ETA: 3s - loss: 0.5913 - binary_accuracy: 0.7423"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.5819 - binary_accuracy: 0.7418Epoch 1/50\n",
            "32/32 [==============================] - 20s 635ms/step - loss: 0.5795 - binary_accuracy: 0.7435 - val_loss: 0.6383 - val_binary_accuracy: 0.7005\n",
            "Epoch 46/50\n",
            "20/32 [=================>............] - ETA: 4s - loss: 0.5893 - binary_accuracy: 0.7349"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.5830 - binary_accuracy: 0.7433Epoch 1/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 20s 627ms/step - loss: 0.5845 - binary_accuracy: 0.7430 - val_loss: 0.6644 - val_binary_accuracy: 0.6771\n",
            "Epoch 47/50\n",
            "13/32 [===========>..................] - ETA: 6s - loss: 0.5881 - binary_accuracy: 0.7400"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.5916 - binary_accuracy: 0.7230Epoch 1/50\n",
            "32/32 [==============================] - 21s 648ms/step - loss: 0.5922 - binary_accuracy: 0.7234 - val_loss: 0.6989 - val_binary_accuracy: 0.6693\n",
            "Epoch 48/50\n",
            "14/32 [============>.................] - ETA: 5s - loss: 0.5867 - binary_accuracy: 0.7407"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.5993 - binary_accuracy: 0.7370Epoch 1/50\n",
            "32/32 [==============================] - 21s 653ms/step - loss: 0.6006 - binary_accuracy: 0.7365 - val_loss: 0.6725 - val_binary_accuracy: 0.6745\n",
            "Epoch 49/50\n",
            "15/32 [=============>................] - ETA: 5s - loss: 0.5890 - binary_accuracy: 0.7375"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.5838 - binary_accuracy: 0.7362Epoch 1/50\n",
            "32/32 [==============================] - 20s 639ms/step - loss: 0.5842 - binary_accuracy: 0.7371 - val_loss: 0.7042 - val_binary_accuracy: 0.6589\n",
            "Epoch 50/50\n",
            "16/32 [==============>...............] - ETA: 5s - loss: 0.5687 - binary_accuracy: 0.7490"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:871: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  ' expressed in bytes should be converted ' +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31/32 [============================>.] - ETA: 0s - loss: 0.5483 - binary_accuracy: 0.7571Epoch 1/50\n",
            "32/32 [==============================] - 20s 637ms/step - loss: 0.5427 - binary_accuracy: 0.7583 - val_loss: 0.6999 - val_binary_accuracy: 0.6667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "uWY8SmY01Ows",
        "outputId": "56f015ef-29b5-4119-c2b1-0cd6a6468980"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41L3xBnt1a-p"
      },
      "source": [
        "### **Fine Tuning last Multiply Layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtK3uD9J1Pyx",
        "outputId": "add97c42-ee3c-46d1-de9a-e65c360e065e"
      },
      "source": [
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'multiply_15':\n",
        "        set_trainable = True\n",
        "        print('yay')\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yay\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjNtUCMf4Gzj",
        "outputId": "054cdc40-d533-4b42-cf91-7d056ff1d109"
      },
      "source": [
        "# Printing out the layers \n",
        "for (i,layer) in enumerate(conv_base.layers):\n",
        "    print(str(i) + \" \"+ layer.__class__.__name__, layer.name, layer.trainable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 InputLayer input_1 False\n",
            "1 Conv2D conv2d False\n",
            "2 BatchNormalization batch_normalization False\n",
            "3 Swish swish False\n",
            "4 DepthwiseConv2D depthwise_conv2d False\n",
            "5 BatchNormalization batch_normalization_1 False\n",
            "6 Swish swish_1 False\n",
            "7 Lambda lambda False\n",
            "8 Conv2D conv2d_1 False\n",
            "9 Swish swish_2 False\n",
            "10 Conv2D conv2d_2 False\n",
            "11 Activation activation False\n",
            "12 Multiply multiply False\n",
            "13 Conv2D conv2d_3 False\n",
            "14 BatchNormalization batch_normalization_2 False\n",
            "15 Conv2D conv2d_4 False\n",
            "16 BatchNormalization batch_normalization_3 False\n",
            "17 Swish swish_3 False\n",
            "18 DepthwiseConv2D depthwise_conv2d_1 False\n",
            "19 BatchNormalization batch_normalization_4 False\n",
            "20 Swish swish_4 False\n",
            "21 Lambda lambda_1 False\n",
            "22 Conv2D conv2d_5 False\n",
            "23 Swish swish_5 False\n",
            "24 Conv2D conv2d_6 False\n",
            "25 Activation activation_1 False\n",
            "26 Multiply multiply_1 False\n",
            "27 Conv2D conv2d_7 False\n",
            "28 BatchNormalization batch_normalization_5 False\n",
            "29 Conv2D conv2d_8 False\n",
            "30 BatchNormalization batch_normalization_6 False\n",
            "31 Swish swish_6 False\n",
            "32 DepthwiseConv2D depthwise_conv2d_2 False\n",
            "33 BatchNormalization batch_normalization_7 False\n",
            "34 Swish swish_7 False\n",
            "35 Lambda lambda_2 False\n",
            "36 Conv2D conv2d_9 False\n",
            "37 Swish swish_8 False\n",
            "38 Conv2D conv2d_10 False\n",
            "39 Activation activation_2 False\n",
            "40 Multiply multiply_2 False\n",
            "41 Conv2D conv2d_11 False\n",
            "42 BatchNormalization batch_normalization_8 False\n",
            "43 DropConnect drop_connect False\n",
            "44 Add add False\n",
            "45 Conv2D conv2d_12 False\n",
            "46 BatchNormalization batch_normalization_9 False\n",
            "47 Swish swish_9 False\n",
            "48 DepthwiseConv2D depthwise_conv2d_3 False\n",
            "49 BatchNormalization batch_normalization_10 False\n",
            "50 Swish swish_10 False\n",
            "51 Lambda lambda_3 False\n",
            "52 Conv2D conv2d_13 False\n",
            "53 Swish swish_11 False\n",
            "54 Conv2D conv2d_14 False\n",
            "55 Activation activation_3 False\n",
            "56 Multiply multiply_3 False\n",
            "57 Conv2D conv2d_15 False\n",
            "58 BatchNormalization batch_normalization_11 False\n",
            "59 Conv2D conv2d_16 False\n",
            "60 BatchNormalization batch_normalization_12 False\n",
            "61 Swish swish_12 False\n",
            "62 DepthwiseConv2D depthwise_conv2d_4 False\n",
            "63 BatchNormalization batch_normalization_13 False\n",
            "64 Swish swish_13 False\n",
            "65 Lambda lambda_4 False\n",
            "66 Conv2D conv2d_17 False\n",
            "67 Swish swish_14 False\n",
            "68 Conv2D conv2d_18 False\n",
            "69 Activation activation_4 False\n",
            "70 Multiply multiply_4 False\n",
            "71 Conv2D conv2d_19 False\n",
            "72 BatchNormalization batch_normalization_14 False\n",
            "73 DropConnect drop_connect_1 False\n",
            "74 Add add_1 False\n",
            "75 Conv2D conv2d_20 False\n",
            "76 BatchNormalization batch_normalization_15 False\n",
            "77 Swish swish_15 False\n",
            "78 DepthwiseConv2D depthwise_conv2d_5 False\n",
            "79 BatchNormalization batch_normalization_16 False\n",
            "80 Swish swish_16 False\n",
            "81 Lambda lambda_5 False\n",
            "82 Conv2D conv2d_21 False\n",
            "83 Swish swish_17 False\n",
            "84 Conv2D conv2d_22 False\n",
            "85 Activation activation_5 False\n",
            "86 Multiply multiply_5 False\n",
            "87 Conv2D conv2d_23 False\n",
            "88 BatchNormalization batch_normalization_17 False\n",
            "89 Conv2D conv2d_24 False\n",
            "90 BatchNormalization batch_normalization_18 False\n",
            "91 Swish swish_18 False\n",
            "92 DepthwiseConv2D depthwise_conv2d_6 False\n",
            "93 BatchNormalization batch_normalization_19 False\n",
            "94 Swish swish_19 False\n",
            "95 Lambda lambda_6 False\n",
            "96 Conv2D conv2d_25 False\n",
            "97 Swish swish_20 False\n",
            "98 Conv2D conv2d_26 False\n",
            "99 Activation activation_6 False\n",
            "100 Multiply multiply_6 False\n",
            "101 Conv2D conv2d_27 False\n",
            "102 BatchNormalization batch_normalization_20 False\n",
            "103 DropConnect drop_connect_2 False\n",
            "104 Add add_2 False\n",
            "105 Conv2D conv2d_28 False\n",
            "106 BatchNormalization batch_normalization_21 False\n",
            "107 Swish swish_21 False\n",
            "108 DepthwiseConv2D depthwise_conv2d_7 False\n",
            "109 BatchNormalization batch_normalization_22 False\n",
            "110 Swish swish_22 False\n",
            "111 Lambda lambda_7 False\n",
            "112 Conv2D conv2d_29 False\n",
            "113 Swish swish_23 False\n",
            "114 Conv2D conv2d_30 False\n",
            "115 Activation activation_7 False\n",
            "116 Multiply multiply_7 False\n",
            "117 Conv2D conv2d_31 False\n",
            "118 BatchNormalization batch_normalization_23 False\n",
            "119 DropConnect drop_connect_3 False\n",
            "120 Add add_3 False\n",
            "121 Conv2D conv2d_32 False\n",
            "122 BatchNormalization batch_normalization_24 False\n",
            "123 Swish swish_24 False\n",
            "124 DepthwiseConv2D depthwise_conv2d_8 False\n",
            "125 BatchNormalization batch_normalization_25 False\n",
            "126 Swish swish_25 False\n",
            "127 Lambda lambda_8 False\n",
            "128 Conv2D conv2d_33 False\n",
            "129 Swish swish_26 False\n",
            "130 Conv2D conv2d_34 False\n",
            "131 Activation activation_8 False\n",
            "132 Multiply multiply_8 False\n",
            "133 Conv2D conv2d_35 False\n",
            "134 BatchNormalization batch_normalization_26 False\n",
            "135 Conv2D conv2d_36 False\n",
            "136 BatchNormalization batch_normalization_27 False\n",
            "137 Swish swish_27 False\n",
            "138 DepthwiseConv2D depthwise_conv2d_9 False\n",
            "139 BatchNormalization batch_normalization_28 False\n",
            "140 Swish swish_28 False\n",
            "141 Lambda lambda_9 False\n",
            "142 Conv2D conv2d_37 False\n",
            "143 Swish swish_29 False\n",
            "144 Conv2D conv2d_38 False\n",
            "145 Activation activation_9 False\n",
            "146 Multiply multiply_9 False\n",
            "147 Conv2D conv2d_39 False\n",
            "148 BatchNormalization batch_normalization_29 False\n",
            "149 DropConnect drop_connect_4 False\n",
            "150 Add add_4 False\n",
            "151 Conv2D conv2d_40 False\n",
            "152 BatchNormalization batch_normalization_30 False\n",
            "153 Swish swish_30 False\n",
            "154 DepthwiseConv2D depthwise_conv2d_10 False\n",
            "155 BatchNormalization batch_normalization_31 False\n",
            "156 Swish swish_31 False\n",
            "157 Lambda lambda_10 False\n",
            "158 Conv2D conv2d_41 False\n",
            "159 Swish swish_32 False\n",
            "160 Conv2D conv2d_42 False\n",
            "161 Activation activation_10 False\n",
            "162 Multiply multiply_10 False\n",
            "163 Conv2D conv2d_43 False\n",
            "164 BatchNormalization batch_normalization_32 False\n",
            "165 DropConnect drop_connect_5 False\n",
            "166 Add add_5 False\n",
            "167 Conv2D conv2d_44 False\n",
            "168 BatchNormalization batch_normalization_33 False\n",
            "169 Swish swish_33 False\n",
            "170 DepthwiseConv2D depthwise_conv2d_11 False\n",
            "171 BatchNormalization batch_normalization_34 False\n",
            "172 Swish swish_34 False\n",
            "173 Lambda lambda_11 False\n",
            "174 Conv2D conv2d_45 False\n",
            "175 Swish swish_35 False\n",
            "176 Conv2D conv2d_46 False\n",
            "177 Activation activation_11 False\n",
            "178 Multiply multiply_11 False\n",
            "179 Conv2D conv2d_47 False\n",
            "180 BatchNormalization batch_normalization_35 False\n",
            "181 Conv2D conv2d_48 False\n",
            "182 BatchNormalization batch_normalization_36 False\n",
            "183 Swish swish_36 False\n",
            "184 DepthwiseConv2D depthwise_conv2d_12 False\n",
            "185 BatchNormalization batch_normalization_37 False\n",
            "186 Swish swish_37 False\n",
            "187 Lambda lambda_12 False\n",
            "188 Conv2D conv2d_49 False\n",
            "189 Swish swish_38 False\n",
            "190 Conv2D conv2d_50 False\n",
            "191 Activation activation_12 False\n",
            "192 Multiply multiply_12 False\n",
            "193 Conv2D conv2d_51 False\n",
            "194 BatchNormalization batch_normalization_38 False\n",
            "195 DropConnect drop_connect_6 False\n",
            "196 Add add_6 False\n",
            "197 Conv2D conv2d_52 False\n",
            "198 BatchNormalization batch_normalization_39 False\n",
            "199 Swish swish_39 False\n",
            "200 DepthwiseConv2D depthwise_conv2d_13 False\n",
            "201 BatchNormalization batch_normalization_40 False\n",
            "202 Swish swish_40 False\n",
            "203 Lambda lambda_13 False\n",
            "204 Conv2D conv2d_53 False\n",
            "205 Swish swish_41 False\n",
            "206 Conv2D conv2d_54 False\n",
            "207 Activation activation_13 False\n",
            "208 Multiply multiply_13 False\n",
            "209 Conv2D conv2d_55 False\n",
            "210 BatchNormalization batch_normalization_41 False\n",
            "211 DropConnect drop_connect_7 False\n",
            "212 Add add_7 False\n",
            "213 Conv2D conv2d_56 False\n",
            "214 BatchNormalization batch_normalization_42 False\n",
            "215 Swish swish_42 False\n",
            "216 DepthwiseConv2D depthwise_conv2d_14 False\n",
            "217 BatchNormalization batch_normalization_43 False\n",
            "218 Swish swish_43 False\n",
            "219 Lambda lambda_14 False\n",
            "220 Conv2D conv2d_57 False\n",
            "221 Swish swish_44 False\n",
            "222 Conv2D conv2d_58 False\n",
            "223 Activation activation_14 False\n",
            "224 Multiply multiply_14 False\n",
            "225 Conv2D conv2d_59 False\n",
            "226 BatchNormalization batch_normalization_44 False\n",
            "227 DropConnect drop_connect_8 False\n",
            "228 Add add_8 False\n",
            "229 Conv2D conv2d_60 False\n",
            "230 BatchNormalization batch_normalization_45 False\n",
            "231 Swish swish_45 False\n",
            "232 DepthwiseConv2D depthwise_conv2d_15 False\n",
            "233 BatchNormalization batch_normalization_46 False\n",
            "234 Swish swish_46 False\n",
            "235 Lambda lambda_15 False\n",
            "236 Conv2D conv2d_61 False\n",
            "237 Swish swish_47 False\n",
            "238 Conv2D conv2d_62 False\n",
            "239 Activation activation_15 False\n",
            "240 Multiply multiply_15 True\n",
            "241 Conv2D conv2d_63 True\n",
            "242 BatchNormalization batch_normalization_47 True\n",
            "243 Conv2D conv2d_64 True\n",
            "244 BatchNormalization batch_normalization_48 True\n",
            "245 Swish swish_48 True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAJaSlxC16CE"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "path = \"/content/drive/MyDrive/Trained Models/Face/EfficientNetB0_New2.h5\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(path,\n",
        "                             monitor=\"val_loss\",\n",
        "                             mode=\"min\",\n",
        "                             save_best_only = True,\n",
        "                             verbose=1)\n",
        "\n",
        "callbacks = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M2vZq8s77sr"
      },
      "source": [
        "###**Fine Tune Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eioQ_n131hxf"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=0.0001),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBmOipOu1n8X"
      },
      "source": [
        "model.save(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "MWh5uY-W2NPY",
        "outputId": "679ae7db-03bf-4a90-8926-181084a159aa"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHjUGccKfWNW"
      },
      "source": [
        "## **Report**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUnzPWXDLNJ1",
        "outputId": "199a53a5-1960-4fa0-8050-ce3d633ecd2c"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "ldFeKv8DLZbJ",
        "outputId": "56182e3b-d83e-4a98-963d-d79166d188c8"
      },
      "source": [
        "!pip uninstall h5py\n",
        "!pip install h5py==2.10.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling h5py-3.1.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/h5py-3.1.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/h5py.libs/libaec-9c9e97eb.so.0.0.10\n",
            "    /usr/local/lib/python3.7/dist-packages/h5py.libs/libhdf5-00e8fae8.so.200.0.0\n",
            "    /usr/local/lib/python3.7/dist-packages/h5py.libs/libhdf5_hl-383c339f.so.200.0.0\n",
            "    /usr/local/lib/python3.7/dist-packages/h5py.libs/libsz-e7aa62f5.so.2.0.1\n",
            "    /usr/local/lib/python3.7/dist-packages/h5py.libs/libz-eb09ad1d.so.1.2.3\n",
            "    /usr/local/lib/python3.7/dist-packages/h5py/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled h5py-3.1.0\n",
            "Collecting h5py==2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Installing collected packages: h5py\n",
            "Successfully installed h5py-2.10.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "h5py"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSB1n1nPMR2h",
        "outputId": "473cbb6d-d8e0-47c0-accc-b363e9a2e8b9"
      },
      "source": [
        "!pip install keras_efficientnets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras_efficientnets\n",
            "  Downloading https://files.pythonhosted.org/packages/3a/41/4dce4e88042b4934003b2b51cfb6a99fc446d375d5fc1ffb2fdf8e069d36/keras_efficientnets-0.1.7-py2.py3-none-any.whl\n",
            "Requirement already satisfied: keras>=2.2.4 in /tensorflow-1.15.2/python3.7 (from keras_efficientnets) (2.3.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.7/dist-packages (from keras_efficientnets) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from keras_efficientnets) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.4->keras_efficientnets) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.4->keras_efficientnets) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.4->keras_efficientnets) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.4->keras_efficientnets) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /tensorflow-1.15.2/python3.7 (from keras>=2.2.4->keras_efficientnets) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.4->keras_efficientnets) (2.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.2->keras_efficientnets) (1.0.1)\n",
            "Installing collected packages: keras-efficientnets\n",
            "Successfully installed keras-efficientnets-0.1.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut18CEzM2TO8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "617a9606-2f28-4476-acd8-abb5625e9f15"
      },
      "source": [
        "import numpy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras_efficientnets import custom_objects\n",
        "\n",
        "# print(custom_objects.get_custom_objects())\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/Trained Models/Face/EfNetB0 tryat1830 3rdMarch.h5')\n",
        "\n",
        "test_generator = ImageDataGenerator()\n",
        "test_data_generator = test_generator.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Sleepy or Awake Faces - Dataset/validation',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    shuffle=False)\n",
        "test_steps_per_epoch = numpy.math.ceil(test_data_generator.samples / test_data_generator.batch_size)\n",
        "\n",
        "predictions = model.predict_generator(test_data_generator, steps=test_steps_per_epoch)\n",
        "# Get most likely class\n",
        "# predicted_classes = numpy.argmax(predictions, axis=1)\n",
        "\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-06b447362ffe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# print(custom_objects.get_custom_objects())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Trained Models/Face/EfNetB0 tryat1830 3rdMarch.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_custom_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtest_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    141\u001b[0m   if (h5py is not None and (\n\u001b[1;32m    142\u001b[0m       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     model = model_config_lib.model_from_config(model_config,\n\u001b[0;32m--> 162\u001b[0;31m                                                custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/saving/model_config.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     53\u001b[0m                     '`Sequential.from_config(config)`?')\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m       printable_module_name='layer')\n\u001b[0m",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     (cls, cls_config) = class_and_config_for_serialized_keras_object(\n\u001b[0;32m--> 180\u001b[0;31m         config, module_objects, custom_objects, printable_module_name)\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[0;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprintable_module_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown layer: Functional"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdA-qwqEhQ9e"
      },
      "source": [
        "true_classes = test_data_generator.classes\n",
        "class_labels = list(test_data_generator.class_indices.keys())  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itZZ-LgPhRtT",
        "outputId": "bd692738-6cc9-423e-826c-d1d627fbd7af"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "print(report)   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       awake       0.50      1.00      0.67       200\n",
            "      sleepy       0.00      0.00      0.00       200\n",
            "\n",
            "    accuracy                           0.50       400\n",
            "   macro avg       0.25      0.50      0.33       400\n",
            "weighted avg       0.25      0.50      0.33       400\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}